from datetime import datetime, date, timedelta
from core.models.article import Article
from .article import UpdateArticle,Update_Over
import core.db as db
from core.wx import WxGather
from core.log import logger
from core.task import TaskScheduler
from core.models.feed import Feed
from core.config import cfg,DEBUG
from core.print import print_info,print_success,print_error,print_warning
from driver.wx import WX_API
from driver.success import Success
wx_db=db.Db(tag="ä»»åŠ¡è°ƒåº¦")

def calculate_pages_from_month_start():
    """è®¡ç®—ä»é…ç½®çš„èµ·å§‹æ—¶é—´åˆ°ç°åœ¨éœ€è¦æŠ“å–çš„é¡µæ•°"""
    today = date.today()
    
    # ä»é…ç½®ä¸­è·å–é‡‡é›†èµ·å§‹æ—¶é—´
    start_date_str = None
    try:
        from core.models.config_management import ConfigManagement
        session = db.DB.get_session()
        try:
            config = session.query(ConfigManagement).filter(
                ConfigManagement.config_key == 'collect_start_date'
            ).first()
            if config and config.config_value:
                start_date_str = config.config_value
        finally:
            session.close()
    except Exception as e:
        logger.warning(f"è¯»å–é‡‡é›†èµ·å§‹æ—¶é—´é…ç½®å¤±è´¥: {e}")
    
    # å¦‚æœæ²¡æœ‰é…ç½®æˆ–é…ç½®æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š2025-12-01
    if not start_date_str:
        start_date_str = '2025-12-01'
    
    try:
        # è§£ææ—¥æœŸå­—ç¬¦ä¸²
        start_date = datetime.strptime(start_date_str, '%Y-%m-%d').date()
    except (ValueError, TypeError):
        # å¦‚æœæ—¥æœŸæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å€¼ï¼š2025-12-01
        logger.warning(f"é‡‡é›†èµ·å§‹æ—¶é—´æ ¼å¼é”™è¯¯: {start_date_str}ï¼Œä½¿ç”¨é»˜è®¤å€¼ 2025-12-01")
        start_date = date(2025, 12, 1)
    
    # ç¡®ä¿èµ·å§‹æ—¥æœŸä¸è¶…è¿‡ä»Šå¤©
    if start_date > today:
        logger.warning(f"é‡‡é›†èµ·å§‹æ—¶é—´ {start_date} è¶…è¿‡ä»Šå¤©ï¼Œä½¿ç”¨ä»Šå¤©ä½œä¸ºèµ·å§‹æ—¶é—´")
        start_date = today
    
    # è®¡ç®—ä»èµ·å§‹æ—¥æœŸåˆ°ç°åœ¨çš„å¤©æ•°
    days_since_start = (today - start_date).days + 1  # +1 åŒ…æ‹¬ä»Šå¤©
    # å‡è®¾æ¯å¤©æœ€å¤šå‘å¸ƒ5ç¯‡æ–‡ç« ï¼ˆä¸€é¡µï¼‰ï¼Œè®¡ç®—éœ€è¦çš„é¡µæ•°
    # ä¸ºäº†ä¿é™©èµ·è§ï¼Œå¤šæŠ“å–ä¸€äº›é¡µæ•°
    estimated_pages = max(1, days_since_start + 2)  # è‡³å°‘1é¡µï¼Œå¤šæŠ“2é¡µä½œä¸ºç¼“å†²
    print_info(f"é‡‡é›†èµ·å§‹æ—¶é—´: {start_date}, é¢„è®¡æŠ“å– {estimated_pages} é¡µ")
    return estimated_pages
def fetch_all_article():
    print("å¼€å§‹æ›´æ–°")
    wx=WxGather().Model()
    try:
        # è·å–å…¬ä¼—å·åˆ—è¡¨
        mps=db.DB.get_all_mps()
        for item in mps:
            try:
                wx.get_Articles(item.faker_id,CallBack=UpdateArticle,Mps_id=item.id,Mps_title=item.mp_name, MaxPage=1)
            except Exception as e:
                print(e)
        print(wx.articles) 
    except Exception as e:
        print(e)         
    finally:
        logger.info(f"æ‰€æœ‰å…¬ä¼—å·æ›´æ–°å®Œæˆ,å…±æ›´æ–°{wx.all_count()}æ¡æ•°æ®")


def test(info:str):
    print("ä»»åŠ¡æµ‹è¯•æˆåŠŸ",info)

from core.models.message_task import MessageTask
# from core.queue import TaskQueue
from .webhook import web_hook
interval=int(cfg.get("interval",60)) # æ¯éš”å¤šå°‘ç§’æ‰§è¡Œä¸€æ¬¡

def get_existing_articles(mp_id: str, limit: int = 10):
    """
    ä»æ•°æ®åº“è·å–æŒ‡å®šå…¬ä¼—å·çš„å·²æœ‰æ–‡ç« 
    
    å‚æ•°:
        mp_id: å…¬ä¼—å·ID
        limit: è·å–æ–‡ç« æ•°é‡é™åˆ¶ï¼Œé»˜è®¤10ç¯‡
        
    è¿”å›:
        æ–‡ç« åˆ—è¡¨ï¼ˆArticleå¯¹è±¡åˆ—è¡¨ï¼‰
    """
    try:
        session = db.DB.get_session()
        try:
            # æŸ¥è¯¢è¯¥å…¬ä¼—å·çš„å·²æœ‰æ–‡ç« ï¼ŒæŒ‰å‘å¸ƒæ—¶é—´é™åºæ’åˆ—
            articles = session.query(Article).filter(
                Article.mp_id == mp_id
            ).order_by(Article.publish_time.desc()).limit(limit).all()
            return articles
        finally:
            session.close()
    except Exception as e:
        logger.error(f"è·å–å·²æœ‰æ–‡ç« å¤±è´¥: {e}")
        return []

def get_article_tags(session, article_ids: list):
    """
    æ‰¹é‡è·å–æ–‡ç« çš„æ ‡ç­¾ä¿¡æ¯
    
    å‚æ•°:
        session: æ•°æ®åº“ä¼šè¯
        article_ids: æ–‡ç« IDåˆ—è¡¨
        
    è¿”å›:
        å­—å…¸ï¼Œkeyä¸ºarticle_idï¼Œvalueä¸ºæ ‡ç­¾åç§°åˆ—è¡¨
    """
    if not article_ids:
        return {}
    
    try:
        from core.models.article_tags import ArticleTag
        from core.models.tags import Tags as TagsModel
        
        # æ‰¹é‡æŸ¥è¯¢æ–‡ç« æ ‡ç­¾å…³è”
        article_tags = session.query(ArticleTag).filter(
            ArticleTag.article_id.in_(article_ids)
        ).all()
        
        # è·å–æ‰€æœ‰æ ‡ç­¾ID
        tag_ids = list(set([at.tag_id for at in article_tags]))
        
        # æ‰¹é‡æŸ¥è¯¢æ ‡ç­¾ä¿¡æ¯
        tags_dict = {}
        if tag_ids:
            tags = session.query(TagsModel).filter(TagsModel.id.in_(tag_ids)).all()
            tags_dict = {t.id: t.name for t in tags}
        
        # æŒ‰æ–‡ç« IDåˆ†ç»„æ ‡ç­¾
        tags_by_article = {}
        for at in article_tags:
            if at.article_id not in tags_by_article:
                tags_by_article[at.article_id] = []
            if at.tag_id in tags_dict:
                tags_by_article[at.article_id].append(tags_dict[at.tag_id])
        
        return tags_by_article
    except Exception as e:
        logger.error(f"è·å–æ–‡ç« æ ‡ç­¾å¤±è´¥: {e}")
        return {}

def get_today_articles(mp_id: str = None):
    """
    ä»æ•°æ®åº“è·å–å½“å¤©çš„æ–‡ç« 
    
    å‚æ•°:
        mp_id: å…¬ä¼—å·IDï¼Œå¦‚æœä¸ºNoneåˆ™è·å–æ‰€æœ‰å…¬ä¼—å·çš„å½“å¤©æ–‡ç« 
        
    è¿”å›:
        æ–‡ç« åˆ—è¡¨ï¼ˆArticleå¯¹è±¡åˆ—è¡¨ï¼‰
    """
    try:
        session = db.DB.get_session()
        try:
            # è®¡ç®—ä»Šå¤©çš„å¼€å§‹æ—¶é—´æˆ³ï¼ˆ0ç‚¹ï¼‰
            today = date.today()
            today_start = int(datetime.combine(today, datetime.min.time()).timestamp())
            # è®¡ç®—æ˜å¤©çš„å¼€å§‹æ—¶é—´æˆ³
            tomorrow_start = int((datetime.combine(today, datetime.min.time()) + timedelta(days=1)).timestamp())
            
            query = session.query(Article).filter(
                Article.publish_time >= today_start,
                Article.publish_time < tomorrow_start
            )
            
            if mp_id:
                query = query.filter(Article.mp_id == mp_id)
            
            # æŒ‰å‘å¸ƒæ—¶é—´é™åºæ’åˆ—
            articles = query.order_by(Article.publish_time.desc()).all()
            return articles
        finally:
            session.close()
    except Exception as e:
        logger.error(f"è·å–å½“å¤©æ–‡ç« å¤±è´¥: {e}")
        return []

def do_job(mp=None,task:MessageTask=None,isTest=False):
        # TaskQueue.add_task(test,info=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        # print("æ‰§è¡Œä»»åŠ¡", task.mps_id)
        if isTest:
            print("æ‰§è¡Œæµ‹è¯•ä»»åŠ¡ï¼ˆä¸æŠ“å–æ–‡ç« ï¼Œä½¿ç”¨å·²æœ‰æ–‡ç« ï¼‰")
        else:
            print("æ‰§è¡Œä»»åŠ¡")
        all_count=0
        wx=WxGather().Model()
        try:
            if isTest:
                # æµ‹è¯•æ¨¡å¼ï¼šä»æ•°æ®åº“è·å–å·²æœ‰æ–‡ç« 
                print_info(f"æµ‹è¯•æ¨¡å¼ï¼šä»æ•°æ®åº“è·å– {mp.mp_name} çš„å·²æœ‰æ–‡ç« ")
                existing_articles = get_existing_articles(mp.id, limit=10)
                if not existing_articles:
                    print_warning(f"å…¬ä¼—å· {mp.mp_name} æ²¡æœ‰å·²æœ‰æ–‡ç« ï¼Œæ— æ³•å‘é€æµ‹è¯•æ¶ˆæ¯")
                    return
                # æ‰¹é‡è·å–æ ‡ç­¾ä¿¡æ¯
                session = db.DB.get_session()
                try:
                    article_ids = [article.id for article in existing_articles]
                    tags_by_article = get_article_tags(session, article_ids)
                finally:
                    session.close()
                
                # å°† Article å¯¹è±¡è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œå…¼å®¹ wx.articles æ ¼å¼
                wx.articles = []
                for article in existing_articles:
                    article_dict = {
                        'id': article.id,
                        'mp_id': article.mp_id,
                        'title': article.title,
                        'pic_url': article.pic_url,
                        'url': article.url,
                        'description': article.description,
                        'publish_time': article.publish_time,
                        'content': getattr(article, 'content', None),
                        'tags': tags_by_article.get(article.id, []),
                        'tag_names': tags_by_article.get(article.id, [])
                    }
                    # æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´
                    if article_dict.get('publish_time'):
                        try:
                            publish_time = article_dict['publish_time']
                            if isinstance(publish_time, (int, float)):
                                from datetime import datetime
                                dt = datetime.fromtimestamp(publish_time)
                                article_dict['publish_time'] = dt.strftime("%Y-%m-%d %H:%M:%S")
                        except Exception as e:
                            print_warning(f"æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´å¤±è´¥: {e}")
                    wx.articles.append(article_dict)
                print_info(f"è·å–åˆ° {len(wx.articles)} ç¯‡å·²æœ‰æ–‡ç« ")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šæŠ“å–æ–°æ–‡ç« 
                # è®¡ç®—ä»æœˆåˆåˆ°ç°åœ¨éœ€è¦æŠ“å–çš„é¡µæ•°
                max_pages = calculate_pages_from_month_start()
                print_info(f"ä»æœˆåˆå¼€å§‹æŠ“å–ï¼Œé¢„è®¡æŠ“å– {max_pages} é¡µ")
                wx.get_Articles(mp.faker_id,CallBack=UpdateArticle,Mps_id=mp.id,Mps_title=mp.mp_name, MaxPage=max_pages,Over_CallBack=Update_Over,interval=interval)
                
                # æŠ“å–å®Œæˆåï¼Œä¸ºæ–‡ç« æ·»åŠ æ ‡ç­¾ä¿¡æ¯
                if wx.articles:
                    # è·å–æ‰€æœ‰æ–‡ç« çš„IDï¼ˆå¦‚æœæ–‡ç« å·²ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
                    article_ids = []
                    for article in wx.articles:
                        if isinstance(article, dict):
                            article_id = article.get('id', '')
                            if article_id:
                                article_ids.append(article_id)
                    
                    # æ‰¹é‡æŸ¥è¯¢æ ‡ç­¾
                    tags_by_article = {}
                    if article_ids:
                        session = db.DB.get_session()
                        try:
                            tags_by_article = get_article_tags(session, article_ids)
                        finally:
                            session.close()
                    
                    # ä¸ºæ–‡ç« æ·»åŠ æ ‡ç­¾ä¿¡æ¯
                    for article in wx.articles:
                        if isinstance(article, dict):
                            article_id = article.get('id', '')
                            if article_id:
                                article['tags'] = tags_by_article.get(article_id, [])
                                article['tag_names'] = tags_by_article.get(article_id, [])
                            else:
                                # å¦‚æœæ–‡ç« è¿˜æ²¡æœ‰IDï¼ˆæ–°æŠ“å–çš„ï¼‰ï¼Œæ ‡ç­¾ä¸ºç©º
                                article['tags'] = []
                                article['tag_names'] = []
        except Exception as e:
            print_error(e)
            # raise
        finally:
            count=wx.all_count()
            all_count+=count
            from jobs.webhook import MessageWebHook 
            tms=MessageWebHook(task=task,feed=mp,articles=wx.articles)
            web_hook(tms)
            if isTest:
                print_success(f"æµ‹è¯•ä»»åŠ¡({task.id})[{mp.mp_name}]æ‰§è¡ŒæˆåŠŸ,ä½¿ç”¨{count}ç¯‡å·²æœ‰æ–‡ç« ")
            else:
                print_success(f"ä»»åŠ¡({task.id})[{mp.mp_name}]æ‰§è¡ŒæˆåŠŸ,{count}æˆåŠŸæ¡æ•°")

from core.queue import TaskQueue

def do_job_all_feeds(feeds: list[Feed] = None, task: MessageTask = None, isTest: bool = False):
    """
    å¤„ç†æ‰€æœ‰å…¬ä¼—å·ï¼Œæ±‡æ€»æ–‡ç« åä¸€æ¬¡æ€§å‘é€
    
    å‚æ•°:
        feeds: å…¬ä¼—å·åˆ—è¡¨
        task: æ¶ˆæ¯ä»»åŠ¡
        isTest: æ˜¯å¦ä¸ºæµ‹è¯•æ¨¡å¼
    """
    # ç¡®ä¿ä½¿ç”¨å…¨å±€ loggerï¼ˆå·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼‰
    global logger
    
    if isTest:
        print("ã€ä»»åŠ¡æ‰§è¡Œã€‘æ‰§è¡Œæµ‹è¯•ä»»åŠ¡ï¼ˆæ±‡æ€»æ‰€æœ‰å…¬ä¼—å·ï¼Œä½¿ç”¨å·²æœ‰æ–‡ç« ï¼‰", flush=True)
        print_info("ã€ä»»åŠ¡æ‰§è¡Œã€‘æ‰§è¡Œæµ‹è¯•ä»»åŠ¡ï¼ˆæ±‡æ€»æ‰€æœ‰å…¬ä¼—å·ï¼Œä½¿ç”¨å·²æœ‰æ–‡ç« ï¼‰")
    else:
        print("ã€ä»»åŠ¡æ‰§è¡Œã€‘æ‰§è¡Œä»»åŠ¡ï¼ˆæ±‡æ€»æ‰€æœ‰å…¬ä¼—å·ï¼‰", flush=True)
        print_info("ã€ä»»åŠ¡æ‰§è¡Œã€‘æ‰§è¡Œä»»åŠ¡ï¼ˆæ±‡æ€»æ‰€æœ‰å…¬ä¼—å·ï¼‰")
    
    all_articles_by_feed = []  # æŒ‰å…¬ä¼—å·åˆ†ç»„çš„æ–‡ç« åˆ—è¡¨
    
    # æ”¶é›†æ‰€æœ‰å…¬ä¼—å·çš„æ–‡ç« 
    for feed in feeds:
        try:
            if isTest:
                # æµ‹è¯•æ¨¡å¼ï¼šä»æ•°æ®åº“è·å–å½“å¤©çš„æ–‡ç« 
                print_info(f"æµ‹è¯•æ¨¡å¼ï¼šä»æ•°æ®åº“è·å– {feed.mp_name} çš„å½“å¤©æ–‡ç« ")
                existing_articles = get_today_articles(feed.id)
                if existing_articles:
                    # æ‰¹é‡è·å–æ ‡ç­¾ä¿¡æ¯
                    session = db.DB.get_session()
                    try:
                        article_ids = [article.id for article in existing_articles]
                        tags_by_article = get_article_tags(session, article_ids)
                    finally:
                        session.close()
                    
                    # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œå¹¶æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´
                    articles_list = []
                    for article in existing_articles:
                        article_dict = {
                            'id': article.id,
                            'mp_id': article.mp_id,
                            'title': article.title or '',
                            'pic_url': article.pic_url or '',
                            'url': article.url or '',
                            'description': article.description or '',
                            'publish_time': article.publish_time,
                            'content': getattr(article, 'content', None),
                            'tags': tags_by_article.get(article.id, []),
                            'tag_names': tags_by_article.get(article.id, [])
                        }
                        # æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´ï¼ˆå¦‚æœæ˜¯æ—¶é—´æˆ³ï¼‰
                        if article_dict.get('publish_time'):
                            try:
                                publish_time = article_dict['publish_time']
                                if isinstance(publish_time, (int, float)):
                                    # æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
                                    from datetime import datetime
                                    dt = datetime.fromtimestamp(publish_time)
                                    article_dict['publish_time'] = dt.strftime("%Y-%m-%d %H:%M:%S")
                                elif isinstance(publish_time, str) and publish_time.isdigit():
                                    # å­—ç¬¦ä¸²æ ¼å¼çš„æ—¶é—´æˆ³
                                    from datetime import datetime
                                    dt = datetime.fromtimestamp(int(publish_time))
                                    article_dict['publish_time'] = dt.strftime("%Y-%m-%d %H:%M:%S")
                            except Exception as e:
                                print_warning(f"æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´å¤±è´¥: {e}, ä½¿ç”¨åŸå§‹å€¼")
                        
                        articles_list.append(article_dict)
                    all_articles_by_feed.append({
                        'feed': feed,
                        'articles': articles_list
                    })
                    print_info(f"è·å–åˆ° {feed.mp_name} çš„ {len(articles_list)} ç¯‡å·²æœ‰æ–‡ç« ")
            else:
                # æ­£å¸¸æ¨¡å¼ï¼šæŠ“å–æ–°æ–‡ç« 
                print_info(f"æŠ“å– {feed.mp_name} çš„æ–°æ–‡ç« ")
                wx = WxGather().Model()
                max_pages = calculate_pages_from_month_start()
                wx.get_Articles(feed.faker_id, CallBack=UpdateArticle, Mps_id=feed.id, Mps_title=feed.mp_name, MaxPage=max_pages, Over_CallBack=Update_Over, interval=interval)
                if wx.articles:
                    # ç»Ÿä¸€è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œå¹¶æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´
                    articles_list = []
                    print_info(f"å¼€å§‹å¤„ç† {feed.mp_name} çš„ {len(wx.articles)} ç¯‡æ–‡ç« ")
                    
                    # æ‰¹é‡è·å–æ ‡ç­¾ä¿¡æ¯ï¼ˆå¦‚æœæ–‡ç« æœ‰IDï¼‰
                    article_ids = []
                    for idx, article in enumerate(wx.articles):
                        if isinstance(article, dict):
                            article_id = str(article.get('id', '')) if article.get('id') is not None else ''
                            if article_id:
                                article_ids.append(article_id)
                        else:
                            article_id = str(getattr(article, 'id', '')) if getattr(article, 'id', None) else ''
                            if article_id:
                                article_ids.append(article_id)
                    
                    # æ‰¹é‡æŸ¥è¯¢æ ‡ç­¾
                    tags_by_article = {}
                    if article_ids:
                        session = db.DB.get_session()
                        try:
                            tags_by_article = get_article_tags(session, article_ids)
                        finally:
                            session.close()
                    
                    for idx, article in enumerate(wx.articles):
                        # è°ƒè¯•ï¼šæ‰“å°åŸå§‹æ–‡ç« æ•°æ®ç»“æ„
                        if idx < 2:  # åªæ‰“å°å‰2ç¯‡
                            print_info(f"  åŸå§‹æ–‡ç«  {idx+1} ç±»å‹: {type(article)}")
                            if isinstance(article, dict):
                                print_info(f"    å­—å…¸é”®: {list(article.keys())}")
                                print_info(f"    titleå€¼: {repr(article.get('title', 'NOT_FOUND'))}")
                                print_info(f"    urlå€¼: {repr(article.get('url', 'NOT_FOUND'))}")
                                print_info(f"    linkå€¼: {repr(article.get('link', 'NOT_FOUND'))}")
                        
                        # å¦‚æœå·²ç»æ˜¯å­—å…¸ï¼Œç¡®ä¿å­—æ®µä¸ä¸º None
                        if isinstance(article, dict):
                            # ç›´æ¥è·å–å­—æ®µå€¼ï¼Œä¸è¿›è¡Œé¢å¤–çš„è½¬æ¢
                            title = article.get('title', '')
                            url = article.get('url', '') or article.get('link', '')
                            article_id = str(article.get('id', '')) if article.get('id') is not None else ''
                            
                            # ç¡®ä¿å­—æ®µæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä¸”ä¸ä¸º None
                            article_dict = {
                                'id': article_id,
                                'mp_id': str(article.get('mp_id', '')) if article.get('mp_id') is not None else '',
                                'title': str(title) if title is not None else '',
                                'pic_url': str(article.get('pic_url', '')) if article.get('pic_url') is not None else '',
                                'url': str(url) if url is not None else '',
                                'description': str(article.get('description', '')) if article.get('description') is not None else '',
                                'publish_time': article.get('publish_time', ''),
                                'content': article.get('content', None),
                                'tags': tags_by_article.get(article_id, []),
                                'tag_names': tags_by_article.get(article_id, [])
                            }
                            
                            # å¦‚æœ title æˆ– url ä¸ºç©ºï¼Œæ‰“å°è­¦å‘Šå’Œå®Œæ•´å­—å…¸å†…å®¹
                            if not article_dict['title'] or not article_dict['url']:
                                print_warning(f"æ–‡ç« æ•°æ®ä¸å®Œæ•´: id={article_dict['id']}, title={repr(title)}, url={repr(url)}")
                                print_warning(f"  åŸå§‹å­—å…¸å®Œæ•´å†…å®¹: {article}")
                            
                            # è°ƒè¯•ï¼šæ‰“å°è½¬æ¢åçš„æ•°æ®
                            if idx < 2:
                                print_info(f"    è½¬æ¢å: title='{article_dict['title'][:50] if article_dict['title'] else '(ç©º)'}', url='{article_dict['url'][:50] if article_dict['url'] else '(ç©º)'}'")
                        else:
                            article_id = str(getattr(article, 'id', '')) if getattr(article, 'id', None) else ''
                            article_dict = {
                                'id': article_id,
                                'mp_id': str(getattr(article, 'mp_id', '')) if getattr(article, 'mp_id', None) else '',
                                'title': str(getattr(article, 'title', '')) if getattr(article, 'title', None) else '',
                                'pic_url': str(getattr(article, 'pic_url', '')) if getattr(article, 'pic_url', None) else '',
                                'url': str(getattr(article, 'url', '') or getattr(article, 'link', '')) if (getattr(article, 'url', None) or getattr(article, 'link', None)) else '',
                                'description': str(getattr(article, 'description', '')) if getattr(article, 'description', None) else '',
                                'publish_time': getattr(article, 'publish_time', ''),
                                'content': getattr(article, 'content', None),
                                'tags': tags_by_article.get(article_id, []),
                                'tag_names': tags_by_article.get(article_id, [])
                            }
                        
                        # æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´ï¼ˆå¦‚æœæ˜¯æ—¶é—´æˆ³ï¼‰
                        if article_dict.get('publish_time'):
                            try:
                                publish_time = article_dict['publish_time']
                                if isinstance(publish_time, (int, float)):
                                    # æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
                                    from datetime import datetime
                                    dt = datetime.fromtimestamp(publish_time)
                                    article_dict['publish_time'] = dt.strftime("%Y-%m-%d %H:%M:%S")
                                elif isinstance(publish_time, str) and publish_time.isdigit():
                                    # å­—ç¬¦ä¸²æ ¼å¼çš„æ—¶é—´æˆ³
                                    from datetime import datetime
                                    dt = datetime.fromtimestamp(int(publish_time))
                                    article_dict['publish_time'] = dt.strftime("%Y-%m-%d %H:%M:%S")
                            except Exception as e:
                                print_warning(f"æ ¼å¼åŒ–å‘å¸ƒæ—¶é—´å¤±è´¥: {e}, ä½¿ç”¨åŸå§‹å€¼")
                        
                        articles_list.append(article_dict)
                    
                    # åªæœ‰å½“æœ‰æ–‡ç« æ—¶æ‰æ·»åŠ åˆ°åˆ—è¡¨
                    if articles_list:
                        all_articles_by_feed.append({
                            'feed': feed,
                            'articles': articles_list
                        })
                        print_info(f"æŠ“å–åˆ° {feed.mp_name} çš„ {len(articles_list)} ç¯‡æ–°æ–‡ç« ")
                    else:
                        print_warning(f"{feed.mp_name} æ²¡æœ‰æŠ“å–åˆ°æ–‡ç« ï¼Œè·³è¿‡")
        except Exception as e:
            print_error(f"å¤„ç†å…¬ä¼—å· {feed.mp_name} æ—¶å‡ºé”™: {e}")
            continue
    
    # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æ–‡ç« ï¼Œç›´æ¥è¿”å›
    if not all_articles_by_feed:
        print_warning("æ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æ–‡ç« ï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
        return
    
    # è®¡ç®—æ€»æ–‡ç« æ•°
    total_articles = sum(len(item['articles']) for item in all_articles_by_feed)
    
    if total_articles == 0:
        print_warning("æ²¡æœ‰æ–‡ç« å¯å‘é€")
        return
    
    # æ„å»ºæ±‡æ€»æ¶ˆæ¯
    from core.lax import TemplateParser
    from core.notice import notice
    
    # ä½¿ç”¨æ±‡æ€»æ¨¡æ¿
    # æ³¨æ„ï¼šTemplateParser æ”¯æŒç‚¹å·è®¿é—®å­—å…¸ï¼Œç›´æ¥éå†åˆ—è¡¨å³å¯ï¼ˆç©ºåˆ—è¡¨ä¸ä¼šæ‰§è¡Œå¾ªç¯ï¼‰
    # ç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½æœ‰é»˜è®¤å€¼ï¼Œé¿å…æ˜¾ç¤ºä¸ºç©º
    default_template = """{{ today }} æ¯æ—¥ç§‘æŠ€èšåˆèµ„è®¯

{% for item in feeds_with_articles %}
## {{ item.feed.mp_name }}

{% for article in item.articles %}
- [**{{ article.title }}**]({{ article.url }}){% if article.tag_names %} ğŸ·ï¸ {{= ', '.join(article.tag_names) if isinstance(article.tag_names, list) else str(article.tag_names) }}{% endif %}
{% endfor %}

{% endfor %}

---
ğŸ“Š å…± {{ total_articles }} ç¯‡æ–‡ç« ï¼Œæ¥è‡ª {{ feeds_count }} ä¸ªå…¬ä¼—å·
"""
    
    # å¦‚æœç”¨æˆ·è‡ªå®šä¹‰äº†æ¨¡æ¿ï¼Œæ£€æŸ¥æ˜¯å¦æ”¯æŒæ±‡æ€»æ ¼å¼
    # å¦‚æœä¸æ”¯æŒï¼Œä½¿ç”¨é»˜è®¤æ±‡æ€»æ¨¡æ¿
    user_template = task.message_template if task.message_template else None
    if user_template and 'feeds_with_articles' in user_template:
        template = user_template
    else:
        template = default_template
    
    parser = TemplateParser(template)
    # ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®ï¼šå°†å­—å…¸åˆ—è¡¨è½¬æ¢ä¸ºæ¨¡æ¿å¯ä»¥è®¿é—®çš„æ ¼å¼
    # TemplateParser æ”¯æŒç‚¹å·è®¿é—®ï¼Œæ‰€ä»¥ item.articles åº”è¯¥å¯ä»¥å·¥ä½œ
    # ä½†ä¸ºäº†ç¡®ä¿å…¼å®¹æ€§ï¼Œæˆ‘ä»¬åŒæ—¶æä¾›ä¸¤ç§æ ¼å¼
    # è·å–ä»Šå¤©çš„æ—¥æœŸ
    today_date = datetime.now().strftime("%Y-%m-%d")
    
    data = {
        "feeds_with_articles": all_articles_by_feed,
        "total_articles": total_articles,
        "feeds_count": len(all_articles_by_feed),
        "task": task,
        'now': today_date,
        'today': today_date
    }
    
    # è°ƒè¯•ï¼šæ‰“å°ä¼ é€’ç»™æ¨¡æ¿çš„æ•°æ®ç»“æ„
    debug_data = "=" * 80 + "\n"
    debug_data += "ã€ä¼ é€’ç»™æ¨¡æ¿çš„æ•°æ®ç»“æ„ã€‘\n"
    debug_data += "=" * 80 + "\n"
    debug_data += f"feeds_with_articles ç±»å‹: {type(data['feeds_with_articles'])}\n"
    debug_data += f"feeds_with_articles é•¿åº¦: {len(data['feeds_with_articles'])}\n"
    if len(data['feeds_with_articles']) > 0:
        first_item = data['feeds_with_articles'][0]
        debug_data += f"ç¬¬ä¸€ä¸ª item ç±»å‹: {type(first_item)}\n"
        debug_data += f"ç¬¬ä¸€ä¸ª item é”®: {list(first_item.keys()) if isinstance(first_item, dict) else 'ä¸æ˜¯å­—å…¸'}\n"
        if isinstance(first_item, dict) and 'articles' in first_item:
            debug_data += f"ç¬¬ä¸€ä¸ª item['articles'] ç±»å‹: {type(first_item['articles'])}\n"
            debug_data += f"ç¬¬ä¸€ä¸ª item['articles'] é•¿åº¦: {len(first_item['articles'])}\n"
            if len(first_item['articles']) > 0:
                first_article = first_item['articles'][0]
                debug_data += f"ç¬¬ä¸€ç¯‡æ–‡ç« ç±»å‹: {type(first_article)}\n"
                debug_data += f"ç¬¬ä¸€ç¯‡æ–‡ç« å†…å®¹: {first_article}\n"
    debug_data += "=" * 80 + "\n"
    print(debug_data, flush=True)
    # logger å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
    logger.info(debug_data)
    
    try:
        # è°ƒè¯•ï¼šæ‰“å°æ•°æ®ç»“æ„ï¼ˆè¯¦ç»†è¾“å‡ºï¼Œç¡®ä¿èƒ½çœ‹åˆ°æ‰€æœ‰ä¿¡æ¯ï¼‰
        import sys
        # logger å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
        
        debug_output = "=" * 80 + "\n"
        debug_output += "ã€æ¨¡æ¿æ¸²æŸ“å‰çš„æ•°æ®ç»“æ„æ£€æŸ¥ã€‘\n"
        debug_output += "=" * 80 + "\n"
        debug_output += f"å‡†å¤‡æ¸²æŸ“æ¨¡æ¿ï¼Œå…± {len(all_articles_by_feed)} ä¸ªå…¬ä¼—å·\n"
        
        for idx, item in enumerate(all_articles_by_feed):
            feed_name = item['feed'].mp_name if hasattr(item['feed'], 'mp_name') else 'æœªçŸ¥'
            articles_count = len(item['articles'])
            debug_output += f"\nå…¬ä¼—å· {idx+1}: {feed_name}\n"
            debug_output += f"  æ–‡ç« æ•°: {articles_count}\n"
            debug_output += f"  itemç±»å‹: {type(item)}\n"
            debug_output += f"  item['articles']ç±»å‹: {type(item['articles'])}\n"
            
            if articles_count > 0:
                debug_output += f"  å‰ {min(3, articles_count)} ç¯‡æ–‡ç« è¯¦æƒ…:\n"
                # æ‰“å°å‰3ç¯‡æ–‡ç« çš„è¯¦ç»†æ•°æ®
                for i, article in enumerate(item['articles'][:3]):
                    if isinstance(article, dict):
                        title = article.get('title', '')
                        url = article.get('url', '')
                        publish_time = article.get('publish_time', '')
                        tag_names = article.get('tag_names', [])
                        tags = article.get('tags', [])
                        debug_output += f"    æ–‡ç«  {i+1}:\n"
                        debug_output += f"      title='{title[:50] if title else '(ç©º)'}'\n"
                        debug_output += f"      url='{url[:50] if url else '(ç©º)'}'\n"
                        debug_output += f"      publish_time='{publish_time}'\n"
                        debug_output += f"      tag_names={tag_names} (ç±»å‹: {type(tag_names)})\n"
                        debug_output += f"      tags={tags} (ç±»å‹: {type(tags)})\n"
                        debug_output += f"      titleç±»å‹={type(title)}, titleå€¼={repr(title)}\n"
                        debug_output += f"      urlç±»å‹={type(url)}, urlå€¼={repr(url)}\n"
                        debug_output += f"      å®Œæ•´æ–‡ç« å­—å…¸: {article}\n"
                    else:
                        debug_output += f"    æ–‡ç«  {i+1}: ä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œç±»å‹={type(article)}\n"
            else:
                debug_output += f"  âš ï¸ å…¬ä¼—å· {feed_name} æ²¡æœ‰æ–‡ç« ï¼\n"
        
        debug_output += "=" * 80 + "\n"
        
        # è¾“å‡ºè°ƒè¯•ä¿¡æ¯
        print(debug_output, flush=True)
        logger.info(debug_output)
        print_info(debug_output)
        
        message = parser.render(data)
        # æ‰“å°å®Œæ•´çš„æ¸²æŸ“åæ¶ˆæ¯ï¼Œç”¨äºè°ƒè¯•ï¼ˆä½¿ç”¨å¤šç§æ–¹å¼ç¡®ä¿è¾“å‡ºå¯è§ï¼‰
        # logger å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
        
        output = "=" * 80 + "\n"
        output += "ã€å®Œæ•´æ¸²æŸ“åçš„æ¶ˆæ¯å†…å®¹ã€‘\n"
        output += "=" * 80 + "\n"
        output += message + "\n"
        output += "=" * 80 + "\n"
        output += f"æ¶ˆæ¯æ€»é•¿åº¦: {len(message)} å­—ç¬¦\n"
        
        # ä½¿ç”¨ print è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º
        print(output, flush=True)
        # ä½¿ç”¨ logger è¾“å‡ºåˆ°æ—¥å¿—
        logger.info(output)
        # ä½¿ç”¨ print_info è¾“å‡ºï¼ˆå¸¦é¢œè‰²ï¼‰
        print_info("=" * 80)
        print_info("ã€å®Œæ•´æ¸²æŸ“åçš„æ¶ˆæ¯å†…å®¹ã€‘")
        print_info("=" * 80)
        print_info(message)
        print_info("=" * 80)
        print_info(f"æ¶ˆæ¯æ€»é•¿åº¦: {len(message)} å­—ç¬¦")
        
        # æ£€æŸ¥ webhook_url æ˜¯å¦ä¸ºç©º
        if not task.web_hook_url:
            print_error(f"ä»»åŠ¡({task.id})çš„ web_hook_url ä¸ºç©ºï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            print_error(f"ä»»åŠ¡åç§°: {task.name}")
            print_error(f"ä»»åŠ¡ID: {task.id}")
            return
        
        print_info(f"å‡†å¤‡å‘é€æ¶ˆæ¯åˆ°: {task.web_hook_url[:50]}...")
        print_info(f"ä»»åŠ¡åç§°: {task.name}")
        print_info(f"æ¶ˆæ¯å†…å®¹é•¿åº¦: {len(message)} å­—ç¬¦")
        
        try:
            result = notice(task.web_hook_url, task.name, message)
            if result:
                print_success(f"ä»»åŠ¡({task.id})æ‰§è¡ŒæˆåŠŸ,æ±‡æ€»äº†{len(all_articles_by_feed)}ä¸ªå…¬ä¼—å·,å…±{total_articles}ç¯‡æ–‡ç« ï¼Œæ¶ˆæ¯å·²å‘é€")
            else:
                print_error(f"ä»»åŠ¡({task.id})æ‰§è¡Œå®Œæˆï¼Œä½†æ¶ˆæ¯å‘é€å¤±è´¥")
        except Exception as e:
            print_error(f"å‘é€æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            print_success(f"ä»»åŠ¡({task.id})æ‰§è¡ŒæˆåŠŸ,æ±‡æ€»äº†{len(all_articles_by_feed)}ä¸ªå…¬ä¼—å·,å…±{total_articles}ç¯‡æ–‡ç« ï¼Œä½†æ¶ˆæ¯å‘é€å¤±è´¥")
    except Exception as e:
        print_error(f"å‘é€æ±‡æ€»æ¶ˆæ¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def add_job(feeds:list[Feed]=None,task:MessageTask=None,isTest=False):
    if isTest:
        TaskQueue.clear_queue()
    
    if not feeds or len(feeds) == 0:
        print_warning("æ²¡æœ‰å…¬ä¼—å·å¯å¤„ç†")
        return
    
    # æ£€æŸ¥ç”¨æˆ·æ¨¡æ¿æ˜¯å¦æ”¯æŒèšåˆæ ¼å¼
    user_template = task.message_template if task.message_template else None
    has_aggregate_template = user_template and 'feeds_with_articles' in user_template
    
    # å¦‚æœåªæœ‰ä¸€ä¸ªå…¬ä¼—å·ï¼Œä¸”ç”¨æˆ·æ¨¡æ¿ä¸åŒ…å« feeds_with_articlesï¼Œä½¿ç”¨å•ä¸ªå…¬ä¼—å·é€»è¾‘
    if len(feeds) == 1 and not has_aggregate_template:
        # å•ä¸ªå…¬ä¼—å·ï¼Œä½¿ç”¨å•ä¸ªå…¬ä¼—å·æ¨¡æ¿
        print_info(f"å•ä¸ªå…¬ä¼—å·æ¨¡å¼ï¼š{feeds[0].mp_name}")
        TaskQueue.add_task(do_job, feeds[0], task, isTest)
        if isTest:
            print(f"æµ‹è¯•ä»»åŠ¡ï¼Œå•ä¸ªå…¬ä¼—å·ï¼ŒåŠ å…¥é˜Ÿåˆ—æˆåŠŸ")
            reload_job()
        else:
            print(f"å•ä¸ªå…¬ä¼—å·ä»»åŠ¡ï¼ŒåŠ å…¥é˜Ÿåˆ—æˆåŠŸ")
    else:
        # å¤šä¸ªå…¬ä¼—å·ï¼Œæˆ–è€…ç”¨æˆ·æ¨¡æ¿åŒ…å« feeds_with_articlesï¼Œä½¿ç”¨èšåˆé€»è¾‘
        print_info(f"èšåˆæ¨¡å¼ï¼š{len(feeds)}ä¸ªå…¬ä¼—å·")
        TaskQueue.add_task(do_job_all_feeds, feeds, task, isTest)
        if isTest:
            print(f"æµ‹è¯•ä»»åŠ¡ï¼Œæ±‡æ€»{len(feeds)}ä¸ªå…¬ä¼—å·ï¼ŒåŠ å…¥é˜Ÿåˆ—æˆåŠŸ")
            reload_job()
        else:
            print(f"æ±‡æ€»ä»»åŠ¡ï¼Œ{len(feeds)}ä¸ªå…¬ä¼—å·ï¼ŒåŠ å…¥é˜Ÿåˆ—æˆåŠŸ")
    
    print_success(TaskQueue.get_queue_info())
    pass
import json
def get_feeds(task:MessageTask=None):
     """
     è·å–ä»»åŠ¡å…³è”çš„å…¬ä¼—å·åˆ—è¡¨
     å¦‚æœ mps_id ä¸ºç©ºæˆ–è§£æåä¸ºç©ºï¼Œè¿”å›æ‰€æœ‰å…¬ä¼—å·
     """
     try:
         mps = json.loads(task.mps_id) if task.mps_id else []
     except:
         mps = []
     
     if len(mps) == 0:
         # å¦‚æœæ²¡æœ‰æŒ‡å®šå…¬ä¼—å·ï¼Œè¿”å›æ‰€æœ‰å…¬ä¼—å·
         mps_list = wx_db.get_all_mps()
     else:
         # è·å–æŒ‡å®šçš„å…¬ä¼—å·
         ids = ",".join([item["id"] for item in mps if "id" in item])
         mps_list = wx_db.get_mps_list(ids) if ids else []
         # å¦‚æœæŒ‡å®šçš„å…¬ä¼—å·ä¸å­˜åœ¨ï¼Œè¿”å›æ‰€æœ‰å…¬ä¼—å·
         if len(mps_list) == 0:
             mps_list = wx_db.get_all_mps()
     return mps_list
scheduler=TaskScheduler()
def reload_job():
    print_success("é‡è½½ä»»åŠ¡")
    scheduler.clear_all_jobs()
    TaskQueue.clear_queue()
    start_job()

def run(job_id:str=None,isTest=False):
    from .taskmsg import get_message_task
    tasks=get_message_task(job_id)
    if not tasks:
        print("æ²¡æœ‰ä»»åŠ¡")
        return None
    for task in tasks:
            #æ·»åŠ æµ‹è¯•ä»»åŠ¡
            print_warning(f"{task.name} æ·»åŠ åˆ°é˜Ÿåˆ—è¿è¡Œ")
            add_job(get_feeds(task),task,isTest=isTest)
            pass
    return tasks
def start_job(job_id:str=None):
    from .taskmsg import get_message_task
    tasks=get_message_task(job_id)
    if not tasks:
        print("æ²¡æœ‰ä»»åŠ¡")
        return
    tag="å®šæ—¶é‡‡é›†"
    for task in tasks:
        cron_exp=task.cron_exp
        if not cron_exp:
            print_error(f"ä»»åŠ¡[{task.id}]æ²¡æœ‰è®¾ç½®cronè¡¨è¾¾å¼")
            continue
      
        job_id=scheduler.add_cron_job(add_job,cron_expr=cron_exp,args=[get_feeds(task),task],job_id=str(task.id),tag="å®šæ—¶é‡‡é›†")
        print(f"å·²æ·»åŠ ä»»åŠ¡: {job_id}, cronè¡¨è¾¾å¼: {cron_exp}")
    
    # æ£€æŸ¥è°ƒåº¦å™¨çŠ¶æ€
    status = scheduler.get_scheduler_status()
    print_info(f"è°ƒåº¦å™¨çŠ¶æ€: running={status['running']}, job_count={status['job_count']}")
    for job_id, next_run_time in status['next_run_times']:
        print_info(f"ä»»åŠ¡ {job_id} ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {next_run_time}")
    
    if not status['running']:
        scheduler.start()
        print_info("è°ƒåº¦å™¨å·²å¯åŠ¨")
    else:
        print_warning("è°ƒåº¦å™¨å·²ç»åœ¨è¿è¡Œä¸­")
def start_all_task():
      #å¼€å¯è‡ªåŠ¨åŒæ­¥æœªåŒæ­¥ æ–‡ç« ä»»åŠ¡
    from jobs.fetch_no_article import start_sync_content
    start_sync_content()
    start_job()
if __name__ == '__main__':
    # do_job()
    # start_all_task()
    pass
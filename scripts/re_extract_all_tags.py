#!/usr/bin/env python3
"""
é‡æ–°æŠ½å–æ‰€æœ‰æ–‡ç« çš„æ ‡ç­¾
åŠŸèƒ½ï¼š
1. éå†æ‰€æœ‰æ–‡ç« ï¼ˆæœ‰å†…å®¹çš„ï¼‰
2. åˆ é™¤æ¯ç¯‡æ–‡ç« çš„æ—§æ ‡ç­¾å…³è”ï¼ˆArticleTagï¼‰
3. é‡æ–°æå–æ ‡ç­¾å¹¶å…³è”
4. ä½¿ç”¨æ–‡ç« çš„å‘å¸ƒæ—¥æœŸä½œä¸ºæ ‡ç­¾æ—¥æœŸ

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/re_extract_all_tags.py
    python scripts/re_extract_all_tags.py --limit 100  # åªå¤„ç†å‰100ç¯‡æ–‡ç« 
    python scripts/re_extract_all_tags.py --mp-id xxx  # åªå¤„ç†æŒ‡å®šå…¬ä¼—å·çš„æ–‡ç« 
    python scripts/re_extract_all_tags.py --dry-run     # åªæŸ¥çœ‹ï¼Œä¸å®é™…ä¿®æ”¹
"""
import sys
import os
import argparse
from datetime import datetime
from typing import Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

# åœ¨å¯¼å…¥é…ç½®ä¹‹å‰ï¼Œå…ˆåŠ è½½ .env æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
env_path = os.path.join(project_root, '.env')
if os.path.exists(env_path):
    try:
        from dotenv import load_dotenv
        load_dotenv(env_path, override=False)  # ä¸è¦†ç›–å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡
        
        # å¦‚æœ DB ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå°è¯•ä» PostgreSQL é…ç½®æ„å»º
        if not os.getenv("DB"):
            postgres_user = os.getenv("POSTGRES_USER", "deepling_user")
            postgres_password = os.getenv("POSTGRES_PASSWORD", "")
            postgres_db = os.getenv("POSTGRES_WERSS_DB") or os.getenv("POSTGRES_DB", "werss_db")
            postgres_host = os.getenv("POSTGRES_HOST", "localhost")
            postgres_port = os.getenv("POSTGRES_PORT", "5432")
            
            # å¦‚æœæ‰¾åˆ°äº† PostgreSQL é…ç½®ï¼Œæ„å»ºè¿æ¥å­—ç¬¦ä¸²
            if postgres_password:
                db_url = f"postgresql://{postgres_user}:{postgres_password}@{postgres_host}:{postgres_port}/{postgres_db}"
                os.environ["DB"] = db_url
                print(f"âœ… å·²ä» .env æ–‡ä»¶æ„å»º PostgreSQL è¿æ¥: postgresql://{postgres_user}:***@{postgres_host}:{postgres_port}/{postgres_db}")
    except ImportError:
        pass  # python-dotenv æœªå®‰è£…æ—¶å¿½ç•¥
    except Exception as e:
        print(f"âš ï¸  åŠ è½½ .env æ–‡ä»¶å¤±è´¥: {e}")

from core.db import DB
from core.models.article import Article
from core.models.article_tags import ArticleTag
from core.models.tags import Tags
from core.models.base import DATA_STATUS
from core.print import print_info, print_success, print_warning, print_error
from core.config import cfg
from sqlalchemy import func, or_


def re_extract_tags_for_article(session, article: Article, dry_run: bool = False) -> dict:
    """
    é‡æ–°æå–å•ç¯‡æ–‡ç« çš„æ ‡ç­¾
    
    Args:
        session: æ•°æ®åº“ä¼šè¯
        article: æ–‡ç« å¯¹è±¡
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼ï¼ˆä¸å®é™…ä¿®æ”¹ï¼‰
        
    Returns:
        dict: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
    """
    result = {
        'article_id': article.id,
        'title': article.title[:50] if article.title else 'æ— æ ‡é¢˜',
        'old_tags_count': 0,
        'new_tags_count': 0,
        'created_tags': [],
        'errors': []
    }
    
    try:
        # 1. è·å–å¹¶åˆ é™¤æ—§çš„æ ‡ç­¾å…³è”
        old_article_tags = session.query(ArticleTag).filter(
            ArticleTag.article_id == article.id
        ).all()
        
        result['old_tags_count'] = len(old_article_tags)
        
        if not dry_run:
            for old_tag in old_article_tags:
                session.delete(old_tag)
            session.flush()  # ç«‹å³æäº¤åˆ é™¤æ“ä½œ
        
        # 2. é‡æ–°æå–æ ‡ç­¾
        if not article.title:
            result['errors'].append("æ–‡ç« æ ‡é¢˜ä¸ºç©ºï¼Œè·³è¿‡")
            return result
        
        # è·å–æ–‡ç« å†…å®¹
        content = article.content if hasattr(article, 'content') and article.content else ""
        description = article.description if article.description else ""
        
        # è°ƒç”¨æ ‡ç­¾æå–æ–¹æ³•
        # æ³¨æ„ï¼šDB æ˜¯å·²ç»å®ä¾‹åŒ–çš„å…¨å±€å¯¹è±¡
        DB._assign_tags_by_extraction(
            session=session,
            article_id=article.id,
            title=article.title,
            description=description,
            content=content
        )
        
        # 3. è·å–æ–°åˆ›å»ºçš„æ ‡ç­¾å…³è”
        new_article_tags = session.query(ArticleTag).filter(
            ArticleTag.article_id == article.id
        ).all()
        
        result['new_tags_count'] = len(new_article_tags)
        
        # è·å–æ–°åˆ›å»ºçš„æ ‡ç­¾åç§°
        if new_article_tags:
            tag_ids = [at.tag_id for at in new_article_tags]
            new_tags = session.query(Tags).filter(Tags.id.in_(tag_ids)).all()
            result['created_tags'] = [tag.name for tag in new_tags]
        
        if not dry_run:
            session.commit()
        else:
            session.rollback()  # è¯•è¿è¡Œæ¨¡å¼ï¼Œå›æ»šæ‰€æœ‰æ›´æ”¹
            
    except Exception as e:
        result['errors'].append(str(e))
        if not dry_run:
            session.rollback()
        print_error(f"å¤„ç†æ–‡ç«  {article.id} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    return result


def re_extract_all_tags(
    limit: Optional[int] = None,
    mp_id: Optional[str] = None,
    dry_run: bool = False,
    batch_size: int = 100
):
    """
    é‡æ–°æå–æ‰€æœ‰æ–‡ç« çš„æ ‡ç­¾
    
    Args:
        limit: é™åˆ¶å¤„ç†çš„æ–‡ç« æ•°é‡ï¼ˆNone è¡¨ç¤ºå¤„ç†æ‰€æœ‰ï¼‰
        mp_id: åªå¤„ç†æŒ‡å®šå…¬ä¼—å·çš„æ–‡ç« ï¼ˆNone è¡¨ç¤ºå¤„ç†æ‰€æœ‰ï¼‰
        dry_run: æ˜¯å¦ä¸ºè¯•è¿è¡Œæ¨¡å¼
        batch_size: æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯æ‰¹æäº¤ä¸€æ¬¡ï¼‰
    """
    print_info("=" * 80)
    print_info("å¼€å§‹é‡æ–°æå–æ‰€æœ‰æ–‡ç« çš„æ ‡ç­¾")
    print_info("=" * 80)
    
    if dry_run:
        print_warning("âš ï¸  è¯•è¿è¡Œæ¨¡å¼ï¼šä¸ä¼šå®é™…ä¿®æ”¹æ•°æ®åº“")
    
    session = DB.get_session()
    
    try:
        # è°ƒè¯•ï¼šæ˜¾ç¤ºæ•°æ®åº“è¿æ¥ä¿¡æ¯
        # æ³¨æ„ï¼šDB æ˜¯å·²ç»å®ä¾‹åŒ–çš„å…¨å±€å¯¹è±¡ï¼Œä¸æ˜¯ç±»
        db_config = DB.connection_str if hasattr(DB, 'connection_str') else cfg.get("db", "") or ""
        print_info(f"ğŸ“Œ æ•°æ®åº“è¿æ¥: {db_config[:50]}..." if len(db_config) > 50 else f"ğŸ“Œ æ•°æ®åº“è¿æ¥: {db_config}")
        
        # ä½¿ç”¨åŸç”Ÿ SQL æŸ¥è¯¢ï¼Œé¿å… ORM é—®é¢˜
        from sqlalchemy import text
        try:
            sql_result = session.execute(text("SELECT COUNT(*) FROM articles"))
            sql_count = sql_result.scalar()
            print_info(f"ğŸ“Š SQL æŸ¥è¯¢æ€»æ–‡ç« æ•°: {sql_count}")
        except Exception as e:
            print_warning(f"SQL æŸ¥è¯¢å¤±è´¥: {e}")
        
        # è°ƒè¯•ï¼šå…ˆæŸ¥çœ‹æ•°æ®åº“ä¸­çš„æ–‡ç« ç»Ÿè®¡ï¼ˆä½¿ç”¨ ORMï¼‰
        all_articles_count = session.query(Article).count()
        print_info(f"ğŸ“Š ORM æŸ¥è¯¢æ€»æ–‡ç« æ•°: {all_articles_count}")
        
        # å°è¯•æŸ¥è¯¢æ‰€æœ‰æ–‡ç« ï¼ˆä¸é™åˆ¶æ¡ä»¶ï¼‰
        all_articles = session.query(Article).limit(5).all()
        print_info(f"ğŸ“Š æŸ¥è¯¢åˆ°çš„æ–‡ç« ç¤ºä¾‹æ•°é‡: {len(all_articles)}")
        if all_articles:
            print_info(f"ğŸ“„ ç¤ºä¾‹æ–‡ç« : {all_articles[0].title[:50] if all_articles[0].title else 'æ— æ ‡é¢˜'}")
            print_info(f"ğŸ“„ ç¤ºä¾‹æ–‡ç« çŠ¶æ€: {all_articles[0].status}")
        
        # æ£€æŸ¥å„ä¸ªæ¡ä»¶
        # æ³¨æ„ï¼šstatus å¯èƒ½ä¸º 0 æˆ– NULLï¼Œéœ€è¦åŒ…å«è¿™äº›æƒ…å†µ
        from sqlalchemy import or_
        not_deleted_count = session.query(Article).filter(
            or_(
                Article.status != DATA_STATUS.DELETED,
                Article.status.is_(None),
                Article.status == 0
            )
        ).count()
        print_info(f"ğŸ“Š æœªåˆ é™¤æ–‡ç« æ•° (status != {DATA_STATUS.DELETED} æˆ– NULL æˆ– 0): {not_deleted_count}")
        
        has_title_count = session.query(Article).filter(
            Article.title.isnot(None),
            Article.title != ''
        ).count()
        print_info(f"ğŸ“Š æœ‰æ ‡é¢˜æ–‡ç« æ•°: {has_title_count}")
        
        # æ£€æŸ¥çŠ¶æ€åˆ†å¸ƒï¼ˆä½¿ç”¨åŸç”Ÿ SQLï¼Œé¿å… ORM é—®é¢˜ï¼‰
        try:
            status_sql = "SELECT status, COUNT(*) as count FROM articles GROUP BY status"
            status_result = session.execute(text(status_sql))
            status_dist = dict(status_result.fetchall())
            print_info(f"ğŸ“Š æ–‡ç« çŠ¶æ€åˆ†å¸ƒ (SQL): {status_dist}")
        except Exception as e:
            print_warning(f"SQL çŠ¶æ€åˆ†å¸ƒæŸ¥è¯¢å¤±è´¥: {e}")
            status_dist = {}
        
        # å°è¯•ä½¿ç”¨ ORM æŸ¥è¯¢çŠ¶æ€åˆ†å¸ƒ
        try:
            status_dist_orm = session.query(Article.status, func.count(Article.id)).group_by(Article.status).all()
            print_info(f"ğŸ“Š æ–‡ç« çŠ¶æ€åˆ†å¸ƒ (ORM): {dict(status_dist_orm)}")
        except Exception as e:
            print_warning(f"ORM çŠ¶æ€åˆ†å¸ƒæŸ¥è¯¢å¤±è´¥: {e}")
        
        # æ„å»ºæŸ¥è¯¢ - å…ˆä¸æ·»åŠ ä»»ä½•è¿‡æ»¤æ¡ä»¶ï¼Œçœ‹çœ‹èƒ½æŸ¥åˆ°å¤šå°‘
        print_info("\nğŸ” æµ‹è¯•æŸ¥è¯¢æ¡ä»¶...")
        query_all = session.query(Article)
        count_all = query_all.count()
        print_info(f"ğŸ“Š æ— è¿‡æ»¤æ¡ä»¶æŸ¥è¯¢: {count_all} ç¯‡")
        
        # é€æ­¥æ·»åŠ è¿‡æ»¤æ¡ä»¶
        # æ³¨æ„ï¼šstatus å¯èƒ½ä¸º NULL æˆ– 0ï¼Œéœ€è¦åŒ…å«è¿™äº›æƒ…å†µ
        query_no_deleted = session.query(Article).filter(
            or_(
                Article.status != DATA_STATUS.DELETED,
                Article.status.is_(None),  # NULL å€¼ä¹ŸåŒ…å«åœ¨å†…
                Article.status == 0  # status = 0 çš„æ–‡ç« ä¹ŸåŒ…å«
            )
        )
        count_no_deleted = query_no_deleted.count()
        print_info(f"ğŸ“Š æ’é™¤å·²åˆ é™¤ (status != {DATA_STATUS.DELETED} æˆ– NULL æˆ– 0): {count_no_deleted} ç¯‡")
        
        query_has_title = session.query(Article).filter(
            Article.title.isnot(None),
            Article.title != ''
        )
        count_has_title = query_has_title.count()
        print_info(f"ğŸ“Š æœ‰æ ‡é¢˜: {count_has_title} ç¯‡")
        
        # æ„å»ºæœ€ç»ˆæŸ¥è¯¢
        # æ³¨æ„ï¼šstatus ä¸º NULL æˆ– 0 çš„æ–‡ç« ä¹Ÿåº”è¯¥å¤„ç†ï¼ˆå¯èƒ½ä¹‹å‰è¢«é‡ç½®äº†ï¼‰
        query = session.query(Article).filter(
            or_(
                Article.status != DATA_STATUS.DELETED,
                Article.status.is_(None),  # NULL å€¼ä¹ŸåŒ…å«åœ¨å†…
                Article.status == 0  # status = 0 çš„æ–‡ç« ä¹ŸåŒ…å«
            ),
            Article.title.isnot(None),  # å¿…é¡»æœ‰æ ‡é¢˜
            Article.title != ''  # æ ‡é¢˜ä¸èƒ½ä¸ºç©º
        )
        
        # å¦‚æœæŒ‡å®šäº†å…¬ä¼—å·IDï¼Œæ·»åŠ è¿‡æ»¤æ¡ä»¶
        if mp_id:
            query = query.filter(Article.mp_id == mp_id)
            print_info(f"ğŸ“Œ åªå¤„ç†å…¬ä¼—å· ID: {mp_id} çš„æ–‡ç« ")
        
        # å…ˆè·å–æ–‡ç« æ€»æ•°ï¼ˆåœ¨åº”ç”¨ limit ä¹‹å‰ï¼‰
        total_count = query.count()
        print_info(f"ğŸ“Š æ‰¾åˆ° {total_count} ç¯‡æ–‡ç« éœ€è¦å¤„ç†")
        
        if total_count == 0:
            print_warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤„ç†çš„æ–‡ç« ")
            return
        
        # æŒ‰å‘å¸ƒæ—¶é—´é™åºæ’åˆ—ï¼ˆå¿…é¡»åœ¨ limit ä¹‹å‰ï¼‰
        query = query.order_by(Article.publish_time.desc())
        
        # å¦‚æœæŒ‡å®šäº†é™åˆ¶æ•°é‡ï¼ˆå¿…é¡»åœ¨ order_by ä¹‹åï¼‰
        if limit:
            query = query.limit(limit)
            print_info(f"ğŸ“Œ é™åˆ¶å¤„ç†æ•°é‡: {limit} ç¯‡")
            # æ›´æ–°å®é™…å¤„ç†æ•°é‡
            total_count = min(limit, total_count)
        
        # ç¡®è®¤æ˜¯å¦ç»§ç»­
        if not dry_run:
            response = input(f"\næ˜¯å¦ç»§ç»­å¤„ç† {total_count} ç¯‡æ–‡ç« ï¼Ÿ(y/n): ")
            if response.lower() != 'y':
                print_info("å·²å–æ¶ˆ")
                return
        
        # å¼€å§‹å¤„ç†
        processed_count = 0
        success_count = 0
        error_count = 0
        total_old_tags = 0
        total_new_tags = 0
        created_tags_set = set()
        
        print_info("\nå¼€å§‹å¤„ç†...")
        print_info("-" * 80)
        
        articles = query.all()
        
        for idx, article in enumerate(articles, 1):
            try:
                print_info(f"\n[{idx}/{total_count}] å¤„ç†æ–‡ç« : {article.title[:60] if article.title else 'æ— æ ‡é¢˜'}")
                print_info(f"   æ–‡ç« ID: {article.id}")
                
                result = re_extract_tags_for_article(session, article, dry_run=dry_run)
                
                processed_count += 1
                
                if result['errors']:
                    error_count += 1
                    print_error(f"   âŒ å¤„ç†å¤±è´¥: {', '.join(result['errors'])}")
                else:
                    success_count += 1
                    total_old_tags += result['old_tags_count']
                    total_new_tags += result['new_tags_count']
                    created_tags_set.update(result['created_tags'])
                    
                    if result['old_tags_count'] > 0:
                        print_info(f"   ğŸ—‘ï¸  åˆ é™¤äº† {result['old_tags_count']} ä¸ªæ—§æ ‡ç­¾å…³è”")
                    if result['new_tags_count'] > 0:
                        print_success(f"   âœ… åˆ›å»ºäº† {result['new_tags_count']} ä¸ªæ–°æ ‡ç­¾å…³è”")
                        if result['created_tags']:
                            print_info(f"   ğŸ“Œ æ ‡ç­¾: {', '.join(result['created_tags'][:5])}")
                            if len(result['created_tags']) > 5:
                                print_info(f"   ... è¿˜æœ‰ {len(result['created_tags']) - 5} ä¸ªæ ‡ç­¾")
                    else:
                        print_warning(f"   âš ï¸  æœªæå–åˆ°ä»»ä½•æ ‡ç­¾")
                
                # æ¯å¤„ç† batch_size ç¯‡æ–‡ç« ï¼Œæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if idx % batch_size == 0:
                    print_info(f"\nğŸ“Š è¿›åº¦: {idx}/{total_count} ({idx*100//total_count}%)")
                    print_info(f"   æˆåŠŸ: {success_count}, å¤±è´¥: {error_count}")
                    if not dry_run:
                        session.commit()  # æ‰¹é‡æäº¤
                        print_info(f"   âœ… å·²æäº¤å‰ {idx} ç¯‡æ–‡ç« çš„æ›´æ”¹")
                
            except KeyboardInterrupt:
                print_warning("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
                if not dry_run:
                    session.rollback()
                break
            except Exception as e:
                error_count += 1
                processed_count += 1
                print_error(f"å¤„ç†æ–‡ç«  {article.id} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                if not dry_run:
                    session.rollback()
                import traceback
                traceback.print_exc()
        
        # æœ€ç»ˆæäº¤
        if not dry_run and processed_count > 0:
            session.commit()
            print_info(f"\nâœ… å·²æäº¤æ‰€æœ‰æ›´æ”¹")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print_info("\n" + "=" * 80)
        print_info("å¤„ç†å®Œæˆç»Ÿè®¡")
        print_info("=" * 80)
        print_info(f"ğŸ“Š æ€»æ–‡ç« æ•°: {total_count}")
        print_info(f"âœ… æˆåŠŸå¤„ç†: {success_count}")
        print_info(f"âŒ å¤„ç†å¤±è´¥: {error_count}")
        print_info(f"ğŸ—‘ï¸  åˆ é™¤çš„æ—§æ ‡ç­¾å…³è”: {total_old_tags}")
        print_info(f"âœ¨ åˆ›å»ºçš„æ–°æ ‡ç­¾å…³è”: {total_new_tags}")
        print_info(f"ğŸ“Œ åˆ›å»ºçš„æ ‡ç­¾æ€»æ•°: {len(created_tags_set)}")
        if created_tags_set:
            print_info(f"ğŸ“Œ æ ‡ç­¾åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰: {', '.join(list(created_tags_set)[:20])}")
            if len(created_tags_set) > 20:
                print_info(f"   ... è¿˜æœ‰ {len(created_tags_set) - 20} ä¸ªæ ‡ç­¾")
        
    except Exception as e:
        print_error(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        if not dry_run:
            session.rollback()
    finally:
        session.close()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="é‡æ–°æŠ½å–æ‰€æœ‰æ–‡ç« çš„æ ‡ç­¾")
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶å¤„ç†çš„æ–‡ç« æ•°é‡ï¼ˆé»˜è®¤ï¼šå¤„ç†æ‰€æœ‰ï¼‰"
    )
    parser.add_argument(
        "--mp-id",
        type=str,
        default=None,
        help="åªå¤„ç†æŒ‡å®šå…¬ä¼—å·IDçš„æ–‡ç« ï¼ˆé»˜è®¤ï¼šå¤„ç†æ‰€æœ‰ï¼‰"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="è¯•è¿è¡Œæ¨¡å¼ï¼šåªæŸ¥çœ‹ï¼Œä¸å®é™…ä¿®æ”¹æ•°æ®åº“"
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=100,
        help="æ‰¹å¤„ç†å¤§å°ï¼ˆæ¯æ‰¹æäº¤ä¸€æ¬¡ï¼Œé»˜è®¤ï¼š100ï¼‰"
    )
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    extract_method = cfg.get("article_tag.extract_method", "textrank")
    max_tags = cfg.get("article_tag.max_topics", 5)
    auto_extract = cfg.get("article_tag.auto_extract", False)
    
    # æ˜¾ç¤ºæ•°æ®åº“è¿æ¥ä¿¡æ¯
    # æ³¨æ„ï¼šDB æ˜¯å·²ç»å®ä¾‹åŒ–çš„å…¨å±€å¯¹è±¡ï¼Œä¸æ˜¯ç±»
    db_config = DB.connection_str if hasattr(DB, 'connection_str') else cfg.get("db", "") or ""
    # éšè—å¯†ç 
    if "@" in db_config:
        import re
        db_config_display = re.sub(r':([^:@]+)@', ':***@', db_config)
    else:
        db_config_display = db_config
    
    print_info("=" * 80)
    print_info("æ ‡ç­¾é‡æ–°æå–è„šæœ¬")
    print_info("=" * 80)
    print_info(f"ğŸ“Œ æ•°æ®åº“: {db_config_display}")
    print_info(f"ğŸ“Œ æå–æ–¹å¼: {extract_method}")
    print_info(f"ğŸ“Œ æœ€å¤§æ ‡ç­¾æ•°: {max_tags}")
    print_info(f"ğŸ“Œ è‡ªåŠ¨æå–: {auto_extract}")
    print_info("=" * 80)
    
    if not auto_extract:
        print_warning("âš ï¸  æ³¨æ„ï¼šé…ç½®ä¸­ auto_extract ä¸º Falseï¼Œä½†è„šæœ¬ä¼šå¼ºåˆ¶æå–æ ‡ç­¾")
    
    # æ‰§è¡Œé‡æ–°æå–
    re_extract_all_tags(
        limit=args.limit,
        mp_id=args.mp_id,
        dry_run=args.dry_run,
        batch_size=args.batch_size
    )


if __name__ == "__main__":
    main()

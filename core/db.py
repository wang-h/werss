from sqlalchemy import create_engine, Engine,Text,event,inspect,text
from sqlalchemy.orm import sessionmaker, declarative_base,scoped_session
from sqlalchemy import Column, Integer, String, DateTime
from sqlalchemy.exc import SQLAlchemyError
from typing import Optional, List
from .models import Feed, Article
from .config import cfg
from core.models.base import Base  
from core.print import print_warning,print_info,print_error,print_success
import logging
import os

# SQLAlchemy æ—¥å¿—çº§åˆ«å°†åœ¨ init æ–¹æ³•ä¸­æ ¹æ®é…ç½®æ–‡ä»¶çš„ debug è®¾ç½®æ¥åŠ¨æ€é…ç½®

# å£°æ˜åŸºç±»
# Base = declarative_base()

class Db:
    connection_str: str=None
    def __init__(self,tag:str="é»˜è®¤",User_In_Thread=True):
        self.Session= None
        self.engine = None
        self.User_In_Thread=User_In_Thread
        self.tag=tag
        print_success(f"[{tag}]è¿æ¥åˆå§‹åŒ–")
        # è·å–æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤å€¼
        db_config = cfg.get("db") or "sqlite:///data/db.db"
        self.init(db_config)
    def get_engine(self) -> Engine:
        """Return the SQLAlchemy engine for this database connection."""
        if self.engine is None:
            raise ValueError("Database connection has not been initialized.")
        return self.engine
    def get_session_factory(self):
        return sessionmaker(bind=self.engine, autoflush=True, expire_on_commit=True, future=True)
    def init(self, con_str: str) -> None:
        """Initialize database connection and create tables"""
        try:
            if con_str is None:
                raise ValueError("Database connection string is None. Please configure 'db' in config.yaml or set DB environment variable.")
            self.connection_str=con_str
            # æ£€æŸ¥SQLiteæ•°æ®åº“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if con_str.startswith('sqlite:///'):
                db_path = con_str[10:]  # å»æ‰'sqlite:///'å‰ç¼€
                if not os.path.exists(db_path):
                    try:
                        os.makedirs(os.path.dirname(db_path), exist_ok=True)
                    except Exception as e:
                        pass
                    open(db_path, 'w').close()
            # æ ¹æ®é…ç½®æ–‡ä»¶çš„ debug è®¾ç½®å†³å®šæ˜¯å¦å¯ç”¨ SQL æ—¥å¿—
            # å¼€å‘ç¯å¢ƒï¼ˆdebug=Trueï¼‰ï¼šæ˜¾ç¤º SQL æ—¥å¿—ï¼ˆINFO çº§åˆ«ï¼‰
            # éƒ¨ç½²ç¯å¢ƒï¼ˆdebug=Falseï¼‰ï¼šä¸æ˜¾ç¤º SQL æ—¥å¿—ï¼ˆWARNING çº§åˆ«ï¼‰
            debug_mode = cfg.get("debug", False)
            db_echo_env = os.getenv("DB_ECHO", "").lower() == "true"
            # å¦‚æœç¯å¢ƒå˜é‡ DB_ECHO æ˜ç¡®è®¾ç½®ä¸º trueï¼Œåˆ™å¯ç”¨ï¼›å¦åˆ™æ ¹æ® debug é…ç½®å†³å®š
            echo_sql = db_echo_env or debug_mode
            
            # é…ç½® SQLAlchemy æ—¥å¿—çº§åˆ«
            if echo_sql:
                # å¼€å‘ç¯å¢ƒï¼šå¯ç”¨ INFO çº§åˆ«çš„ SQL æ—¥å¿—
                logging.getLogger('sqlalchemy.engine').setLevel(logging.INFO)
                logging.getLogger('sqlalchemy.pool').setLevel(logging.INFO)
                logging.getLogger('sqlalchemy.dialects').setLevel(logging.INFO)
            else:
                # éƒ¨ç½²ç¯å¢ƒï¼šç¦ç”¨ SQL æ—¥å¿—ï¼ˆåªæ˜¾ç¤º WARNING åŠä»¥ä¸Šçº§åˆ«ï¼‰
                logging.getLogger('sqlalchemy.engine').setLevel(logging.WARNING)
                logging.getLogger('sqlalchemy.pool').setLevel(logging.WARNING)
                logging.getLogger('sqlalchemy.dialects').setLevel(logging.WARNING)
            
            self.engine = create_engine(con_str,
                                     pool_size=2,          # æœ€å°ç©ºé—²è¿æ¥æ•°
                                     max_overflow=20,      # å…è®¸çš„æœ€å¤§æº¢å‡ºè¿æ¥æ•°
                                     pool_timeout=30,      # è·å–è¿æ¥æ—¶çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
                                     echo=echo_sql,        # æ ¹æ®é…ç½®æ–‡ä»¶çš„ debug è®¾ç½®æ§åˆ¶ SQL æ—¥å¿—
                                     pool_recycle=60,  # è¿æ¥æ± å›æ”¶æ—¶é—´ï¼ˆç§’ï¼‰
                                     isolation_level="AUTOCOMMIT",  # è®¾ç½®éš”ç¦»çº§åˆ«
                                    #  isolation_level="READ COMMITTED",  # è®¾ç½®éš”ç¦»çº§åˆ«
                                    #  query_cache_size=0,
                                     connect_args={"check_same_thread": False} if con_str.startswith('sqlite:///') else {}
                                     )
            self.session_factory=self.get_session_factory()
            
            # è‡ªåŠ¨æ‰§è¡Œæ•°æ®åº“è¿ç§»ï¼ˆæ£€æµ‹å¹¶æ·»åŠ ç¼ºå¤±çš„å­—æ®µï¼‰
            try:
                self.migrate_tables()
            except Exception as e:
                print_warning(f"è‡ªåŠ¨è¿ç§»æ‰§è¡Œå¤±è´¥ï¼ˆä¸å½±å“å¯åŠ¨ï¼‰: {e}")
        except Exception as e:
            print(f"Error creating database connection: {e}")
            raise
    def create_tables(self):
        """Create all tables defined in models"""
        from core.models.base import Base as B # å¯¼å…¥æ‰€æœ‰æ¨¡å‹
        try:
            B.metadata.create_all(self.engine)
            print_success('æ‰€æœ‰è¡¨åˆ›å»ºæˆåŠŸï¼')
        except Exception as e:
            print_error(f"åˆ›å»ºè¡¨å¤±è´¥: {e}")
    
    def migrate_tables(self):
        """
        è‡ªåŠ¨è¿ç§»æ•°æ®åº“è¡¨ç»“æ„
        æ£€æµ‹æ¨¡å‹å®šä¹‰ä¸æ•°æ®åº“è¡¨ç»“æ„çš„å·®å¼‚ï¼Œè‡ªåŠ¨æ·»åŠ ç¼ºå¤±çš„å­—æ®µ
        """
        from core.models.base import Base as B
        from sqlalchemy import inspect as sql_inspect
        
        try:
            inspector = sql_inspect(self.engine)
            
            # éå†æ‰€æœ‰æ¨¡å‹
            for table_name, table in B.metadata.tables.items():
                if not inspector.has_table(table_name):
                    # è¡¨ä¸å­˜åœ¨ï¼Œåˆ›å»ºè¡¨
                    print_info(f"ğŸ“¦ åˆ›å»ºæ–°è¡¨: {table_name}")
                    table.create(self.engine, checkfirst=True)
                else:
                    # è¡¨å­˜åœ¨ï¼Œæ£€æŸ¥å­—æ®µå·®å¼‚
                    existing_columns = {col['name']: col for col in inspector.get_columns(table_name)}
                    model_columns = {col.name: col for col in table.columns}
                    
                    # æ£€æŸ¥ç¼ºå¤±çš„å­—æ®µ
                    for col_name, model_col in model_columns.items():
                        if col_name not in existing_columns:
                            # å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å­—æ®µ
                            self._add_column(table_name, col_name, model_col)
            
            print_success('âœ… æ•°æ®åº“è¿ç§»å®Œæˆ')
        except Exception as e:
            print_error(f"æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _add_column(self, table_name: str, column_name: str, column: Column):
        """
        æ·»åŠ å­—æ®µåˆ°ç°æœ‰è¡¨
        
        Args:
            table_name: è¡¨å
            column_name: å­—æ®µå
            column: SQLAlchemy Column å¯¹è±¡
        """
        try:
            # æ„å»º ALTER TABLE è¯­å¥
            if self.connection_str and ('postgresql' in self.connection_str or 'postgres' in self.connection_str):
                # PostgreSQL è¯­æ³•
                col_type = str(column.type)
                nullable = "NULL" if column.nullable else "NOT NULL"
                default = ""
                
                # å¤„ç†é»˜è®¤å€¼
                if column.default is not None:
                    if hasattr(column.default, 'arg'):
                        default_val = column.default.arg
                        if isinstance(default_val, bool):
                            default = f" DEFAULT {str(default_val).upper()}"
                        elif isinstance(default_val, (int, float)):
                            default = f" DEFAULT {default_val}"
                        else:
                            default = f" DEFAULT '{default_val}'"
                    elif callable(column.default):
                        # å¯è°ƒç”¨çš„é»˜è®¤å€¼ï¼ˆå¦‚å‡½æ•°ï¼‰
                        default = ""
                
                alter_sql = f'ALTER TABLE "{table_name}" ADD COLUMN "{column_name}" {col_type} {nullable}{default}'
            else:
                # SQLite/MySQL è¯­æ³•
                col_type = str(column.type)
                nullable = "" if column.nullable else "NOT NULL"
                default = ""
                
                if column.default is not None:
                    if hasattr(column.default, 'arg'):
                        default_val = column.default.arg
                        if isinstance(default_val, bool):
                            default = f" DEFAULT {1 if default_val else 0}"
                        elif isinstance(default_val, (int, float)):
                            default = f" DEFAULT {default_val}"
                        else:
                            default = f" DEFAULT '{default_val}'"
                
                alter_sql = f"ALTER TABLE {table_name} ADD COLUMN {column_name} {col_type} {nullable}{default}"
            
            # æ‰§è¡Œ ALTER TABLE
            with self.engine.begin() as conn:
                conn.execute(text(alter_sql))
            
            print_success(f"  âœ… æ·»åŠ å­—æ®µ: {table_name}.{column_name}")
            
            # å¦‚æœæ˜¯ PostgreSQLï¼Œæ·»åŠ æ³¨é‡Š
            if self.connection_str and ('postgresql' in self.connection_str or 'postgres' in self.connection_str):
                if hasattr(column, 'comment') and column.comment:
                    comment_sql = f"COMMENT ON COLUMN \"{table_name}\".\"{column_name}\" IS '{column.comment}';"
                    try:
                        with self.engine.begin() as conn:
                            conn.execute(text(comment_sql))
                    except:
                        pass  # æ³¨é‡Šæ·»åŠ å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
                        
        except SQLAlchemyError as e:
            # å¦‚æœå­—æ®µå·²å­˜åœ¨æˆ–å…¶ä»–é”™è¯¯ï¼Œè®°å½•ä½†ä¸ä¸­æ–­
            error_msg = str(e)
            if "already exists" in error_msg or "duplicate column" in error_msg.lower():
                print_info(f"  â„¹ï¸  å­—æ®µå·²å­˜åœ¨: {table_name}.{column_name}")
            else:
                print_warning(f"  âš ï¸  æ·»åŠ å­—æ®µå¤±è´¥ {table_name}.{column_name}: {error_msg}")    
        
    def close(self) -> None:
        """Close the database connection"""
        if self.SESSION:
            self.SESSION.close()
            self.SESSION.remove()
            
    def __enter__(self):
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
    def delete_article(self,article_data:dict)->bool:
        try:
            art = Article(**article_data)
            if art.id:
               art.id=f"{str(art.mp_id)}-{art.id}".replace("MP_WXS_","")
            session=DB.get_session()
            article = session.query(Article).filter(Article.id == art.id).first()
            if article is not None:
                session.delete(article)
                session.commit()
                return True
        except Exception as e:
            print_error(f"delete article:{str(e)}")
            pass      
        return False
     
    def add_article(self, article_data: dict,check_exist=False) -> bool:
        try:
            session=self.get_session()
            from datetime import datetime, date
            art = Article(**article_data)
            if art.id:
               art.id=f"{str(art.mp_id)}-{art.id}".replace("MP_WXS_","")
            
            # æ£€æŸ¥æ–‡ç« çš„å‘å¸ƒæ—¶é—´æ˜¯å¦æ—©äºé…ç½®çš„é‡‡é›†èµ·å§‹æ—¶é—´
            if art.publish_time:
                try:
                    # ä»é…ç½®ä¸­è·å–é‡‡é›†èµ·å§‹æ—¶é—´
                    from core.models.config_management import ConfigManagement
                    config = session.query(ConfigManagement).filter(
                        ConfigManagement.config_key == 'collect_start_date'
                    ).first()
                    
                    if config and config.config_value:
                        try:
                            start_date = datetime.strptime(config.config_value, '%Y-%m-%d').date()
                            # å°† publish_time è½¬æ¢ä¸ºæ—¥æœŸè¿›è¡Œæ¯”è¾ƒ
                            if isinstance(art.publish_time, (int, float)):
                                # å¦‚æœæ˜¯æ—¶é—´æˆ³ï¼Œè½¬æ¢ä¸ºæ—¥æœŸ
                                publish_timestamp = int(art.publish_time)
                                if publish_timestamp < 10000000000:  # ç§’çº§æ—¶é—´æˆ³
                                    publish_timestamp *= 1000
                                publish_date = datetime.fromtimestamp(publish_timestamp / 1000).date()
                            else:
                                # å¦‚æœæ˜¯ datetime å¯¹è±¡ï¼Œç›´æ¥è·å–æ—¥æœŸ
                                publish_date = art.publish_time.date() if hasattr(art.publish_time, 'date') else art.publish_time
                            
                            # å¦‚æœæ–‡ç« å‘å¸ƒæ—¶é—´æ—©äºèµ·å§‹æ—¶é—´ï¼Œè·³è¿‡ä¿å­˜
                            if publish_date < start_date:
                                print_info(f"æ–‡ç« å‘å¸ƒæ—¶é—´ {publish_date} æ—©äºé‡‡é›†èµ·å§‹æ—¶é—´ {start_date}ï¼Œè·³è¿‡ä¿å­˜: {art.title[:50]}")
                                return False
                        except (ValueError, TypeError, AttributeError) as e:
                            # æ—¥æœŸè§£æå¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­ä¿å­˜
                            print_warning(f"è§£æé‡‡é›†èµ·å§‹æ—¶é—´æˆ–æ–‡ç« å‘å¸ƒæ—¶é—´å¤±è´¥: {e}")
                except Exception as e:
                    # è¯»å–é…ç½®å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­ä¿å­˜ï¼ˆä½¿ç”¨é»˜è®¤è¡Œä¸ºï¼‰
                    print_warning(f"è¯»å–é‡‡é›†èµ·å§‹æ—¶é—´é…ç½®å¤±è´¥: {e}")
            
            # å§‹ç»ˆæ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºIDï¼‰
            existing_article = session.query(Article).filter(Article.id == art.id).first()
            if existing_article is not None:
                if check_exist:
                    print_warning(f"Article already exists: {art.id}")
                    return False
                else:
                    # å¦‚æœå·²å­˜åœ¨ä½†ä¸è¦æ±‚æ£€æŸ¥ï¼Œå¯ä»¥é€‰æ‹©æ›´æ–°æˆ–è·³è¿‡
                    # è¿™é‡Œé€‰æ‹©è·³è¿‡ï¼Œé¿å…é‡å¤æ’å…¥
                    print_info(f"Article already exists, skipping: {art.id}")
                    return False
                
            if art.created_at is None:
                art.created_at=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            if art.updated_at is None:
                art.updated_at=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            art.created_at=datetime.strptime(art.created_at ,'%Y-%m-%d %H:%M:%S')
            art.updated_at=datetime.strptime(art.updated_at,'%Y-%m-%d %H:%M:%S')
            art.content=art.content
            from core.models.base import DATA_STATUS
            art.status=DATA_STATUS.ACTIVE
            session.add(art)
            session.flush()  # å…ˆ flush è·å– article.id
            
            # ========== è‡ªåŠ¨æå–æ ‡ç­¾ ==========
            try:
                # åŸºäºæ–‡ç« å†…å®¹è‡ªåŠ¨æå–æ ‡ç­¾ï¼ˆä¼šè‡ªåŠ¨åˆ›å»ºæ–°æ ‡ç­¾ï¼‰
                auto_extract_enabled = cfg.get("article_tag.auto_extract", True)
                print_info(f"ğŸ” æ ‡ç­¾æå–é…ç½®: auto_extract={auto_extract_enabled}")
                
                if auto_extract_enabled:
                    content_length = len(art.content or "")
                    print_info(f"ğŸ“ æ–‡ç« å†…å®¹é•¿åº¦: {content_length}, æ ‡é¢˜: {art.title[:50]}")
                    self._assign_tags_by_extraction(
                        session, 
                        art.id, 
                        art.title, 
                        art.description or "", 
                        art.content or ""
                    )
                else:
                    print_warning("âš ï¸  æ ‡ç­¾è‡ªåŠ¨æå–å·²ç¦ç”¨")
            except Exception as tag_error:
                # æ ‡ç­¾æå–å¤±è´¥ä¸å½±å“æ–‡ç« ä¿å­˜
                print_warning(f"è‡ªåŠ¨æå–æ ‡ç­¾å¤±è´¥: {tag_error}")
                import traceback
                traceback.print_exc()
            # ==========================================
            
            sta=session.commit()
            
        except Exception as e:
            # å¤„ç†å„ç§æ•°æ®åº“çš„å”¯ä¸€çº¦æŸé”™è¯¯
            error_str = str(e)
            if "UNIQUE" in error_str or "Duplicate entry" in error_str or "UniqueViolation" in error_str or "duplicate key" in error_str.lower():
                print_warning(f"Article already exists (duplicate key): {art.id}")
                # å°è¯•å›æ»šï¼Œé¿å…äº‹åŠ¡é—®é¢˜
                try:
                    session.rollback()
                except:
                    pass
                return False
            else:
                print_error(f"Failed to add article: {e}")
                import traceback
                traceback.print_exc()
                try:
                    session.rollback()
                except:
                    pass
                return False
        return True    
        
    def get_articles(self, id:str=None, limit:int=30, offset:int=0) -> List[Article]:
        try:
            data = self.get_session().query(Article).limit(limit).offset(offset)
            return data
        except Exception as e:
            print(f"Failed to fetch Feed: {e}")
            return e    
             
    def get_all_mps(self) -> List[Feed]:
        """Get all Feed records"""
        try:
            return self.get_session().query(Feed).all()
        except Exception as e:
            print(f"Failed to fetch Feed: {e}")
            return e
            
    def get_mps_list(self, mp_ids:str) -> List[Feed]:
        try:
            ids=mp_ids.split(',')
            data =  self.get_session().query(Feed).filter(Feed.id.in_(ids)).all()
            return data
        except Exception as e:
            print(f"Failed to fetch Feed: {e}")
            return e
    def get_mps(self, mp_id:str) -> Optional[Feed]:
        try:
            ids=mp_id.split(',')
            data =  self.get_session().query(Feed).filter_by(id= mp_id).first()
            return data
        except Exception as e:
            print(f"Failed to fetch Feed: {e}")
            return e

    def get_faker_id(self, mp_id:str):
        data = self.get_mps(mp_id)
        return data.faker_id
    def expire_all(self):
        if self.Session:
            self.Session.expire_all()    
    def bind_event(self,session):
        # Session Events
        @event.listens_for(session, 'before_commit')
        def receive_before_commit(session):
            print("Transaction is about to be committed.")

        @event.listens_for(session, 'after_commit')
        def receive_after_commit(session):
            print("Transaction has been committed.")

        # Connection Events
        @event.listens_for(self.engine, 'connect')
        def connect(dbapi_connection, connection_record):
            print("New database connection established.")

        @event.listens_for(self.engine, 'close')
        def close(dbapi_connection, connection_record):
            print("Database connection closed.")
    def get_session(self):
        """è·å–æ–°çš„æ•°æ®åº“ä¼šè¯"""
        UseInThread=self.User_In_Thread
        def _session():
            if UseInThread:
                self.Session=scoped_session(self.session_factory)
                # self.Session=self.session_factory
            else:
                self.Session=self.session_factory
            # self.bind_event(self.Session)
            return self.Session
        
        
        if self.Session is None:
            _session()
        
        session = self.Session()
        # session.expire_all()
        # session.expire_on_commit = True  # ç¡®ä¿æ¯æ¬¡æäº¤åå¯¹è±¡è¿‡æœŸ
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å·²ç»å…³é—­
        if not session.is_active:
            from core.print import print_info
            print_info(f"[{self.tag}] Session is already closed.")
            _session()
            return self.Session()
        # æ£€æŸ¥æ•°æ®åº“è¿æ¥æ˜¯å¦å·²æ–­å¼€
        try:
            from core.models import User
            # å°è¯•æ‰§è¡Œä¸€ä¸ªç®€å•çš„æŸ¥è¯¢æ¥æ£€æŸ¥è¿æ¥çŠ¶æ€
            session.query(User.id).count()
        except Exception as e:
            from core.print import print_warning
            print_warning(f"[{self.tag}] Database connection lost: {e}. Reconnecting...")
            self.init(self.connection_str)
            _session()
            return self.Session()
        return session
    def auto_refresh(self):
        # å®šä¹‰ä¸€ä¸ªäº‹ä»¶ç›‘å¬å™¨ï¼Œåœ¨å¯¹è±¡æ›´æ–°åè‡ªåŠ¨åˆ·æ–°
        def receive_after_update(mapper, connection, target):
            print(f"Refreshing object: {target}")
        from core.models import MessageTask,Article
        event.listen(Article,'after_update', receive_after_update)
        event.listen(MessageTask,'after_update',receive_after_update)
        
    def session_dependency(self):
        """FastAPIä¾èµ–é¡¹ï¼Œç”¨äºè¯·æ±‚èŒƒå›´çš„ä¼šè¯ç®¡ç†"""
        session = self.get_session()
        try:
            yield session
        finally:
            session.remove()
    
    def _assign_tags_by_extraction(self, session, article_id: str, title: str, description: str = "", content: str = ""):
        """ä½¿ç”¨æå–æ–¹å¼è‡ªåŠ¨æå–æ ‡ç­¾å¹¶å…³è”ï¼ˆæ ‡ç­¾å­˜å‚¨åœ¨ tags è¡¨ï¼Œé€šè¿‡ article_tags å…³è”ï¼‰"""
        try:
            from core.models.tags import Tags
            from core.models.article_tags import ArticleTag
            from core.tag_extractor import TagExtractor
            import uuid
            from datetime import datetime
            
            # è·å–æå–æ–¹å¼
            extract_method = cfg.get("article_tag.extract_method", "textrank")
            
            # ä½¿ç”¨å…¨å±€å•ä¾‹æå–å™¨ï¼ˆæ¨¡å‹å¸¸é©»å†…å­˜ï¼‰
            from core.tag_extractor import get_tag_extractor
            extractor = get_tag_extractor()
            
            # æå–æ ‡ç­¾å…³é”®è¯
            if extract_method == "ai":
                # AI æå–æ˜¯å¼‚æ­¥çš„ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                import asyncio
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_running():
                        # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œä½¿ç”¨çº¿ç¨‹æ± 
                        import concurrent.futures
                        with concurrent.futures.ThreadPoolExecutor() as executor:
                            future = executor.submit(
                                asyncio.run,
                                extractor.extract_with_ai(
                                    title, 
                                    description, 
                                    content,
                                    cfg.get("article_tag.max_topics", 3)
                                )
                            )
                            topics = future.result()
                    else:
                        topics = asyncio.run(extractor.extract_with_ai(
                            title, 
                            description, 
                            content,
                            cfg.get("article_tag.max_topics", 3)
                        ))
                except RuntimeError:
                    topics = asyncio.run(extractor.extract_with_ai(
                        title, 
                        description, 
                        content,
                        cfg.get("article_tag.max_topics", 3)
                    ))
                except Exception as ai_error:
                    print_warning(f"âš ï¸  AI æå–å¤±è´¥ï¼Œå›é€€åˆ° TextRank: {ai_error}")
                    # AI æå–å¤±è´¥æ—¶å›é€€åˆ° TextRank
                    topics = extractor.extract(title, description, content, method="textrank")
                    print_info(f"ğŸ” TextRank æå–åˆ° {len(topics)} ä¸ªå…³é”®è¯: {topics}")
            else:
                # TextRank æˆ– KeyBERT æå–ï¼ˆåŒæ­¥ï¼‰
                try:
                    topics = extractor.extract(title, description, content, method=extract_method)
                    print_info(f"ğŸ” {extract_method} æå–åˆ° {len(topics)} ä¸ªå…³é”®è¯: {topics}")
                except Exception as extract_error:
                    print_warning(f"âš ï¸  {extract_method} æå–å¤±è´¥: {extract_error}")
                    # æå–å¤±è´¥æ—¶å°è¯•ä½¿ç”¨ TextRank ä½œä¸ºåå¤‡
                    topics = extractor.extract(title, description, content, method="textrank")
                    print_info(f"ğŸ” TextRank æå–åˆ° {len(topics)} ä¸ªå…³é”®è¯: {topics}")
            
            if not topics:
                print_warning(f"âš ï¸  æœªæå–åˆ°ä»»ä½•å…³é”®è¯ï¼Œæ ‡é¢˜: {title[:50]}")
                return
            
            assigned_count = 0
            auto_create = True  # å§‹ç»ˆå¯ç”¨è‡ªåŠ¨åˆ›å»ºæ ‡ç­¾
            
            # è·å–æ–‡ç« çš„å‘å¸ƒæ—¥æœŸï¼Œç”¨äºè®¾ç½®æ ‡ç­¾çš„åˆ›å»ºæ—¶é—´
            article = session.query(Article).filter(Article.id == article_id).first()
            tag_created_at = datetime.now()  # é»˜è®¤ä½¿ç”¨å½“å‰æ—¶é—´
            if article and article.publish_time:
                try:
                    # å°† publish_timeï¼ˆæ—¶é—´æˆ³ï¼‰è½¬æ¢ä¸º datetime
                    publish_timestamp = int(article.publish_time)
                    if publish_timestamp < 10000000000:  # ç§’çº§æ—¶é—´æˆ³
                        publish_timestamp *= 1000
                    tag_created_at = datetime.fromtimestamp(publish_timestamp / 1000)
                except Exception as e:
                    print_warning(f"è½¬æ¢æ–‡ç« å‘å¸ƒæ—¶é—´å¤±è´¥ï¼Œä½¿ç”¨å½“å‰æ—¶é—´: {e}")
                    tag_created_at = datetime.now()
            
            for topic_name in topics:
                # æŸ¥æ‰¾åŒ¹é…çš„æ ‡ç­¾
                tag = session.query(Tags).filter(
                    Tags.name == topic_name,
                    Tags.status == 1
                ).first()
                
                if tag:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨å…³è”
                    existing = session.query(ArticleTag).filter(
                        ArticleTag.article_id == article_id,
                        ArticleTag.tag_id == tag.id
                    ).first()
                    
                    if not existing:
                        article_tag = ArticleTag(
                            id=str(uuid.uuid4()),
                            article_id=article_id,
                            tag_id=tag.id,
                            created_at=datetime.now(),  # å…³è”åˆ›å»ºæ—¶é—´ï¼ˆå½“å‰æ—¶é—´ï¼‰
                            article_publish_date=tag_created_at  # æ–‡ç« çš„å‘å¸ƒæ—¥æœŸï¼ˆç”¨äºè¶‹åŠ¿ç»Ÿè®¡ï¼‰
                        )
                        session.add(article_tag)
                        assigned_count += 1
                elif auto_create:
                    # è‡ªåŠ¨åˆ›å»ºæ–°æ ‡ç­¾ï¼ˆæ‰€æœ‰æ¨¡å¼éƒ½æ”¯æŒï¼‰
                    try:
                        import json
                        new_tag = Tags(
                            id=str(uuid.uuid4()),
                            name=topic_name,
                            cover="",
                            intro=f"è‡ªåŠ¨åˆ›å»ºçš„æ ‡ç­¾ï¼š{topic_name}",
                            mps_id="[]",  # ç©ºæ•°ç»„
                            status=1,
                            created_at=tag_created_at,  # ä½¿ç”¨æ–‡ç« çš„å‘å¸ƒæ—¥æœŸ
                            updated_at=tag_created_at   # ä½¿ç”¨æ–‡ç« çš„å‘å¸ƒæ—¥æœŸ
                        )
                        session.add(new_tag)
                        session.flush()  # è·å–æ–°æ ‡ç­¾çš„ ID
                        
                        article_tag = ArticleTag(
                            id=str(uuid.uuid4()),
                            article_id=article_id,
                            tag_id=new_tag.id,
                            created_at=datetime.now(),  # å…³è”åˆ›å»ºæ—¶é—´ï¼ˆå½“å‰æ—¶é—´ï¼‰
                            article_publish_date=tag_created_at  # æ–‡ç« çš„å‘å¸ƒæ—¥æœŸï¼ˆç”¨äºè¶‹åŠ¿ç»Ÿè®¡ï¼‰
                        )
                        session.add(article_tag)
                        assigned_count += 1
                        print_success(f"âœ… è‡ªåŠ¨åˆ›å»ºæ ‡ç­¾: {topic_name}")
                    except Exception as e:
                        print_warning(f"è‡ªåŠ¨åˆ›å»ºæ ‡ç­¾å¤±è´¥: {e}")
            
            if assigned_count > 0:
                print_success(f"âœ… æ–‡ç«  {article_id} å·²å…³è” {assigned_count} ä¸ªæ ‡ç­¾ï¼ˆåŸºäºæå–ï¼‰")
            else:
                print_warning(f"âš ï¸  æ–‡ç«  {article_id} æœªå…³è”ä»»ä½•æ ‡ç­¾")
        except Exception as e:
            print_error(f"æå–æ ‡ç­¾å¹¶å…³è”å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

# å…¨å±€æ•°æ®åº“å®ä¾‹
DB = Db(User_In_Thread=True)
# åˆå§‹åŒ–å·²åœ¨ __init__ ä¸­å®Œæˆï¼Œè¿™é‡Œä¸éœ€è¦å†æ¬¡è°ƒç”¨